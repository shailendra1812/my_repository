{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.141.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: urllib3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "    \n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with the webdriver & Maximize the window:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# Go Into URL:\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search_Bar:\n",
    "\n",
    "search_columns=driver.find_element_by_id(\"searchInput\")\n",
    "search_columns.send_keys(\"most viewed videos on YouTube\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on search_button:\n",
    "\n",
    "search_button=driver.find_element_by_id(\"searchButton\")\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 most-viewed YouTube videos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>-</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>-</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>-</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>-</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                              Name                          Artist  \\\n",
       "0    1.                  Baby Shark Dance  Pinkfong Kids' Songs & Stories   \n",
       "1    2.                         Despacito                      Luis Fonsi   \n",
       "2    3.              Johny Johny Yes Papa                               -   \n",
       "3    4.                      Shape of You                      Ed Sheeran   \n",
       "4    5.                     See You Again                     Wiz Khalifa   \n",
       "5    6.                                 -                               -   \n",
       "6    7.                       Uptown Funk                     Mark Ronson   \n",
       "7    8.                                 -                               -   \n",
       "8    9.                                 -      Cocomelon – Nursery Rhymes   \n",
       "9   10.                     Gangnam Style                             Psy   \n",
       "10  11.                                 -                       ChuChu TV   \n",
       "11  12.                             Sugar                        Maroon 5   \n",
       "12  13.                             Sorry                   Justin Bieber   \n",
       "13  14.                    Dame Tu Cosita                       El Chombo   \n",
       "14  15.                              Roar                      Katy Perry   \n",
       "15  16.                    Counting Stars                     OneRepublic   \n",
       "16  17.                 Thinking Out Loud                      Ed Sheeran   \n",
       "17  18.                        Dark Horse                      Katy Perry   \n",
       "18  19.                             Faded                     Alan Walker   \n",
       "19  20.                                 -      Cocomelon – Nursery Rhymes   \n",
       "20  21.                      Shake It Off                    Taylor Swift   \n",
       "21  22.                           Lean On                     Major Lazer   \n",
       "22  23.                    Girls Like You                        Maroon 5   \n",
       "23  24.                          Bailando                Enrique Iglesias   \n",
       "24  25.                        Let Her Go                       Passenger   \n",
       "25  26.                          Mi Gente                        J Balvin   \n",
       "26  27.                           Perfect                      Ed Sheeran   \n",
       "27  28.  Waka Waka (This Time for Africa)                         Shakira   \n",
       "28  29.                             Hello                           Adele   \n",
       "29  30.                            Axel F                      Crazy Frog   \n",
       "\n",
       "          Upload_date Views  \n",
       "0       June 17, 2016  8.79  \n",
       "1    January 12, 2017  7.40  \n",
       "2     October 8, 2016  5.46  \n",
       "3    January 30, 2017  5.35  \n",
       "4       April 6, 2015  5.14  \n",
       "5    January 31, 2012  4.44  \n",
       "6   November 19, 2014  4.20  \n",
       "7   February 27, 2018  4.15  \n",
       "8         May 2, 2018  4.14  \n",
       "9       July 15, 2012  4.09  \n",
       "10      March 6, 2014  3.92  \n",
       "11   January 14, 2015  3.48  \n",
       "12   October 22, 2015  3.44  \n",
       "13      April 5, 2018  3.39  \n",
       "14  September 5, 2013  3.37  \n",
       "15       May 31, 2013  3.32  \n",
       "16    October 7, 2014  3.27  \n",
       "17  February 20, 2014  3.09  \n",
       "18   December 3, 2015  3.08  \n",
       "19       May 24, 2018  3.08  \n",
       "20    August 18, 2014  3.07  \n",
       "21     March 22, 2015  3.05  \n",
       "22       May 31, 2018  3.05  \n",
       "23     April 11, 2014  3.04  \n",
       "24      July 25, 2012  3.01  \n",
       "25      June 29, 2017  2.93  \n",
       "26   November 9, 2017  2.87  \n",
       "27       June 4, 2010  2.85  \n",
       "28   October 22, 2015  2.84  \n",
       "29      June 16, 2009  2.83  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making Empty list:\n",
    "\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "# Scrap the Rank of the Song from tabel:\n",
    "\n",
    "for i in range(1,31):\n",
    "    try:\n",
    "        rank=driver.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[{}]/td[1]\".format(i))\n",
    "        Rank.append(rank.text)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append(\"-\")\n",
    "        \n",
    "# Scrap the Name of the Song from tabel:\n",
    "\n",
    "for i in range(1,31):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[{}]/td[2]/a\".format(i))\n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append(\"-\")\n",
    "        \n",
    "        \n",
    "# Scrap the Artist of the Song from tabel:\n",
    "\n",
    "for i in range(1,31):\n",
    "    try:\n",
    "        artist=driver.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[{}]/td[3]/a\".format(i))\n",
    "        Artist.append(artist.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist.append(\"-\")\n",
    "        \n",
    "# Scrap the upload_date of the Song from tabel:\n",
    "\n",
    "for i in range(1,31):\n",
    "    try:\n",
    "        date=driver.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[{}]/td[5]\".format(i))\n",
    "        Upload_date.append(date.text)\n",
    "    except NoSuchElementException:\n",
    "        Upload_date.append(\"-\")\n",
    "        \n",
    "# Scrap the Views of the Song from tabel:        \n",
    "for i in range(1,31):\n",
    "    try:\n",
    "        view=driver.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[3]/tbody/tr[{}]/td[4]\".format(i))\n",
    "        Views.append(view.text)\n",
    "    except NoSuchElementException:\n",
    "        Views.append(\"-\")\n",
    "        \n",
    "        \n",
    "# Mking the dataframe of scraped data:\n",
    "\n",
    "print(\"Top 30 most-viewed YouTube videos\")\n",
    "\n",
    "DataFrame=pd.DataFrame({\"Rank\":Rank,\"Name\":Name,\"Artist\":Artist,\"Upload_date\":Upload_date,\"Views\":Views})\n",
    "DataFrame\n",
    "\n",
    "# Save the data into csv format:\n",
    "\n",
    "DataFrame.to_csv(\"Top 30 most-viewed YouTube videos\")\n",
    "\n",
    "# Close the driver:\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Scrape the details team India’s international fixtures from bcci.tv?\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "    \n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with the webdriver & Maximize the window:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# Go Into URL:\n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on menu button:\n",
    "\n",
    "menu_button=driver.find_element_by_xpath(\"//button[@class='navigation__header-button menu-button js-navigation-menu-button']\")\n",
    "menu_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on international button:\n",
    "\n",
    "button=driver.find_element_by_xpath(\"//div[@class='navigation__expand']\")\n",
    "button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on fixture_button:\n",
    "\n",
    "fixture_button=driver.find_element_by_xpath(\"//a[@class='navigation__link navigation__link--in-drop-down']\")\n",
    "fixture_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ST ODI</td>\n",
       "      <td>Sri Lanka v India 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Tuesday 13 July</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ND ODI</td>\n",
       "      <td>Sri Lanka v India 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Friday 16 July</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3RD ODI</td>\n",
       "      <td>Sri Lanka v India 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Sunday 18 July</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ST T20I</td>\n",
       "      <td>Sri Lanka v India 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Wednesday 21 July</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2ND T20I</td>\n",
       "      <td>Sri Lanka v India 2021</td>\n",
       "      <td></td>\n",
       "      <td>Friday 23 July</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3RD T20I</td>\n",
       "      <td>Sri Lanka v India 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>Sunday 25 July</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1ST TEST</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>Wednesday 4 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2ND TEST</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>Thursday 12 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3RD TEST</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>Wednesday 25 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4TH TEST</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>Thursday 2 September</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5TH TEST</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>Friday 10 September</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_Title                  Series                         Place  \\\n",
       "0        FINAL                       -                             -   \n",
       "1      1ST ODI  Sri Lanka v India 2021  R Premadasa Stadium, Colombo   \n",
       "2      2ND ODI  Sri Lanka v India 2021  R Premadasa Stadium, Colombo   \n",
       "3      3RD ODI  Sri Lanka v India 2021  R Premadasa Stadium, Colombo   \n",
       "4     1ST T20I  Sri Lanka v India 2021  R Premadasa Stadium, Colombo   \n",
       "5     2ND T20I  Sri Lanka v India 2021                                 \n",
       "6     3RD T20I  Sri Lanka v India 2021  R Premadasa Stadium, Colombo   \n",
       "7     1ST TEST    England v India 2021      Trent Bridge, Nottingham   \n",
       "8     2ND TEST    England v India 2021                Lord's, London   \n",
       "9     3RD TEST    England v India 2021             Headingley, Leeds   \n",
       "10    4TH TEST    England v India 2021              The Oval, London   \n",
       "11    5TH TEST    England v India 2021      Old Trafford, Manchester   \n",
       "\n",
       "                    Date       Time  \n",
       "0                      -          -  \n",
       "1        Tuesday 13 July  14:30 IST  \n",
       "2         Friday 16 July  14:30 IST  \n",
       "3         Sunday 18 July  14:30 IST  \n",
       "4      Wednesday 21 July  19:00 IST  \n",
       "5         Friday 23 July  19:00 IST  \n",
       "6         Sunday 25 July  19:00 IST  \n",
       "7     Wednesday 4 August  15:30 IST  \n",
       "8     Thursday 12 August  15:30 IST  \n",
       "9    Wednesday 25 August  15:30 IST  \n",
       "10  Thursday 2 September  15:30 IST  \n",
       "11   Friday 10 September  15:30 IST  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating empty list:\n",
    "\n",
    "urls=[]\n",
    "Match_Title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "\n",
    "# Scrap the url:\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='js-match event-list-item fixture is-live t-test fixture--long event-list-item--long ']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='js-match event-list-item fixture  t-odi fixture--long event-list-item--long ']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='js-match event-list-item fixture  t-t20i fixture--long event-list-item--long ']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='js-match event-list-item fixture  t-test fixture--long event-list-item--long ']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "\n",
    "# Scrap the match_title:\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        match=driver.find_element_by_xpath(\"//span[@class='mc-header-info__match-description-match-type mc-theme-color']\")\n",
    "        Match_Title.append(match.text)\n",
    "    except NoSuchElementException:\n",
    "        Match_Title.append(\"-\")\n",
    "        \n",
    "\n",
    "# Scrap the series:\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        series=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[2]/section[3]/div/ul/li[1]/span[2]\")\n",
    "        Series.append(series.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append(\"-\")\n",
    "        \n",
    "# scrap the place:\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        place=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[2]/section[3]/div/ul/li[3]/span[2]\")\n",
    "        Place.append(place.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append(\"-\")\n",
    "        \n",
    "# scrap the Date:\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        date=driver.find_element_by_xpath(\"/html/body/div[1]/div/header/div/div[2]/div/div[4]/strong\")\n",
    "        Date.append(date.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append(\"-\")\n",
    "        \n",
    "# Scrap the time:\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        time=driver.find_element_by_xpath(\"/html/body/div[1]/div/header/div/div[2]/div/div[4]/span[1]\")\n",
    "        Time.append(time.text)\n",
    "    except NoSuchElementException:\n",
    "        Time.append(\"-\")\n",
    "        \n",
    "# Creating Dataframe:\n",
    "\n",
    "DataFrame=pd.DataFrame({\"Match_Title\":Match_Title,\"Series\":Series,\"Place\":Place,\"Date\":Date,\"Time\":Time})\n",
    "DataFrame\n",
    "\n",
    "# Save the data:\n",
    "\n",
    "DataFrame.to_csv(\"international fixtures\")\n",
    "\n",
    "# close the driver:\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com?\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "    \n",
    "A) Name\n",
    "\n",
    "B) Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to webdriver and maximize the window:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# Goto the url:\n",
    "\n",
    "driver.get(\"https://www.guru99.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on selenium button:\n",
    "\n",
    "selenium_button=driver.find_element_by_xpath(\"/html/body/div[2]/section[4]/div/div/div/div/div/div/div/div[1]/div/ul[1]/li[3]/a\")\n",
    "selenium_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the advertisment:\n",
    "\n",
    "close=driver.find_element_by_xpath(\"//div[@class='cb-close']\")\n",
    "close.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the another advertisement:\n",
    "\n",
    "close_adt=driver.find_element_by_id(\"Layer_1\")\n",
    "close_adt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll the page until you you are not reach at selenium_exception_handeling_topic:\n",
    "\n",
    "selenium=driver.find_element_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[2]\")\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\",selenium)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on selenium_tutorial:\n",
    "\n",
    "selenium_tutorial=driver.find_element_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]/a/strong\")\n",
    "selenium_tutorial.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can't be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty list:\n",
    "\n",
    "Name=[]\n",
    "Description=[]\n",
    "\n",
    "\n",
    "# Scrap the name from the given tabel:\n",
    "\n",
    "for i in range(2,43):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"//table[@class='table table-striped']/tbody/tr[{}]/td[1]\".format(i))\n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append(\"-\")\n",
    "\n",
    "# Scrap the description from the tabel: \n",
    "\n",
    "for i in range(2,43):\n",
    "    try:\n",
    "        desc=driver.find_element_by_xpath(\"//table[@class='table table-striped']/tbody/tr[{}]/td[2]\".format(i))\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append(\"-\")\n",
    "        \n",
    "# creating DataFrame:\n",
    "        \n",
    "DataFrame=pd.DataFrame({\"Name\":Name,\"Description\":Description})\n",
    "DataFrame\n",
    "\n",
    "\n",
    "# Save the data into csv format:\n",
    "\n",
    "DataFrame.to_csv(\"selenium exception handling\")\n",
    "\n",
    "# close the driver:\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com?\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "    \n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP at current price (19-20)\n",
    "\n",
    "D) GSDP at current price (18-19)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the driver and maximize the window:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# get the url:\n",
    "\n",
    "driver.get(\"http://statisticstimes.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on Economy:\n",
    "\n",
    "Economy_button=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "Economy_button.click()\n",
    "\n",
    "# Click on India:\n",
    "\n",
    "india=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "india.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on GDP on indian state:\n",
    "\n",
    "india_state=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "india_state.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price (19-20)  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     1,845,853   \n",
       "2     3              Uttar Pradesh                     1,687,818   \n",
       "3     4                    Gujarat                             -   \n",
       "4     5                  Karnataka                     1,631,977   \n",
       "5     6                West Bengal                     1,253,832   \n",
       "6     7                  Rajasthan                     1,020,989   \n",
       "7     8             Andhra Pradesh                       972,782   \n",
       "8     9                  Telangana                       969,604   \n",
       "9    10             Madhya Pradesh                       906,672   \n",
       "10   11                     Kerala                             -   \n",
       "11   12                      Delhi                       856,112   \n",
       "12   13                    Haryana                       831,610   \n",
       "13   14                      Bihar                       611,804   \n",
       "14   15                     Punjab                       574,760   \n",
       "15   16                     Odisha                       521,275   \n",
       "16   17                      Assam                             -   \n",
       "17   18               Chhattisgarh                       329,180   \n",
       "18   19                  Jharkhand                       328,598   \n",
       "19   20                Uttarakhand                             -   \n",
       "20   21            Jammu & Kashmir                             -   \n",
       "21   22           Himachal Pradesh                       165,472   \n",
       "22   23                        Goa                        80,449   \n",
       "23   24                    Tripura                        55,984   \n",
       "24   25                 Chandigarh                             -   \n",
       "25   26                 Puducherry                        38,253   \n",
       "26   27                  Meghalaya                        36,572   \n",
       "27   28                     Sikkim                        32,496   \n",
       "28   29                    Manipur                        31,790   \n",
       "29   30                   Nagaland                             -   \n",
       "30   31          Arunachal Pradesh                             -   \n",
       "31   32                    Mizoram                        26,503   \n",
       "32   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP at current price (18-19) Share(18-19) GDP($ billion)  \n",
       "0                      2,632,792       13.94%        399.921  \n",
       "1                      1,630,208        8.63%        247.629  \n",
       "2                      1,584,764        8.39%        240.726  \n",
       "3                      1,502,899        7.96%        228.290  \n",
       "4                      1,493,127        7.91%        226.806  \n",
       "5                      1,089,898        5.77%        165.556  \n",
       "6                        942,586        4.99%        143.179  \n",
       "7                        862,957        4.57%        131.083  \n",
       "8                        861,031        4.56%        130.791  \n",
       "9                        809,592        4.29%        122.977  \n",
       "10                       781,653        4.14%        118.733  \n",
       "11                       774,870        4.10%        117.703  \n",
       "12                       734,163        3.89%        111.519  \n",
       "13                       530,363        2.81%         80.562  \n",
       "14                       526,376        2.79%         79.957  \n",
       "15                       487,805        2.58%         74.098  \n",
       "16                       315,881        1.67%         47.982  \n",
       "17                       304,063        1.61%         46.187  \n",
       "18                       297,204        1.57%         45.145  \n",
       "19                       245,895        1.30%         37.351  \n",
       "20                       155,956        0.83%         23.690  \n",
       "21                       153,845        0.81%         23.369  \n",
       "22                        73,170        0.39%         11.115  \n",
       "23                        49,845        0.26%          7.571  \n",
       "24                        42,114        0.22%          6.397  \n",
       "25                        34,433        0.18%          5.230  \n",
       "26                        33,481        0.18%          5.086  \n",
       "27                        28,723        0.15%          4.363  \n",
       "28                        27,870        0.15%          4.233  \n",
       "29                        27,283        0.14%          4.144  \n",
       "30                        24,603        0.13%          3.737  \n",
       "31                        22,287        0.12%          3.385  \n",
       "32                             -            -              -  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating blank list: \n",
    "\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP1=[]\n",
    "GSDP2=[]\n",
    "Share=[]\n",
    "GDP=[]\n",
    "\n",
    "# Scrap rank from the tabel:\n",
    "\n",
    "for i in range(1,34):\n",
    "    try:\n",
    "        rank=driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[{}]/td[1]\".format(i))\n",
    "        Rank.append(rank.text)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append(\"-\")\n",
    "        \n",
    "# Scrap State from the tabel:\n",
    "\n",
    "for i in range(1,34):\n",
    "    try:\n",
    "        state=driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[{}]/td[2]\".format(i))\n",
    "        State.append(state.text)\n",
    "    except NoSuchElementException:\n",
    "        State.append(\"-\")\n",
    "        \n",
    "# Scrap GSDP at current price (19-20) from tabel:\n",
    "\n",
    "for i in range(1,34):\n",
    "    try:\n",
    "        gsdp1=driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[{}]/td[3]\".format(i))\n",
    "        GSDP1.append(gsdp1.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP1.append(\"-\")\n",
    "\n",
    "# Scrap GSDP at current price (18-19) from tabel:\n",
    "\n",
    "for i in range(1,34):\n",
    "    try:\n",
    "        gsdp2=driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[{}]/td[4]\".format(i))\n",
    "        GSDP2.append(gsdp2.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP2.append(\"-\")\n",
    "\n",
    "# Scrap Share(18-19) from tabel:        \n",
    "\n",
    "for i in range(1,34):\n",
    "    try:\n",
    "        share=driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[{}]/td[5]\".format(i))\n",
    "        Share.append(share.text)\n",
    "    except NoSuchElementException:\n",
    "        Share.append(\"-\")\n",
    "        \n",
    "# Scrap GDP($ billion) from tabel:\n",
    "        \n",
    "for i in range(1,34):\n",
    "    try:\n",
    "        gdp=driver.find_element_by_xpath(\"/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr[{}]/td[6]\".format(i))\n",
    "        GDP.append(gdp.text)\n",
    "    except NoSuchElementException:\n",
    "        GDP.append(\"-\")\n",
    "        \n",
    "# creating dataframe:\n",
    "\n",
    "DataFrame=pd.DataFrame({\"Rank\":Rank,\"State\":State,\"GSDP at current price (19-20)\":GSDP1,\n",
    "                       \"GSDP at current price (18-19)\":GSDP2,\"Share(18-19)\":Share,\"GDP($ billion)\":GDP})\n",
    "DataFrame\n",
    "\n",
    "\n",
    "# Save the dataframe:\n",
    "\n",
    "DataFrame.to_csv(\"State-wise GDP of India\")\n",
    "\n",
    "# Close the driver:\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the driver and maximize the window:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# go into url:\n",
    "\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on menu button:\n",
    "\n",
    "menu_button=driver.find_element_by_xpath(\"//button[@class='btn-link d-lg-none mt-1 js-details-target']\")\n",
    "menu_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on Enterprice button:\n",
    "\n",
    "Enterprice_button=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "Enterprice_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on trending button:\n",
    "\n",
    "try:\n",
    "    Trending=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "    Trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    print(\"No_Access\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programthink/zhao</td>\n",
       "      <td>【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AkashSingh3031/The-Complete-FAANG-Preparation</td>\n",
       "      <td>This repository contains all the DSA (Data-Str...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CaffeineMC/sodium-fabric</td>\n",
       "      <td>A Fabric mod designed to improve frame rates a...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n8n-io/n8n</td>\n",
       "      <td>Free and open fair-code licensed node based Wo...</td>\n",
       "      <td>174</td>\n",
       "      <td>TypeScript,94.9%,Vue,4.9%,SCSS,0.1%,JavaScript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebookresearch/AugLy</td>\n",
       "      <td>A data augmentations library for audio, image,...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python,100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vxunderground/MalwareSourceCode</td>\n",
       "      <td>Collection of malware source code for a variet...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abuanwar072/Flutter-Responsive-Admin-Panel-or-...</td>\n",
       "      <td>Responsive Admin Panel or Dashboard using Flutter</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EssayKillerBrain/EssayKiller_V2</td>\n",
       "      <td>基于开源GPT2.0的初代创作型人工智能 | 可扩展、可进化</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>organicmaps/organicmaps</td>\n",
       "      <td>🍃 Organic Maps is a better fork of MAPS.ME, an...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rustdesk/rustdesk</td>\n",
       "      <td>Yet another remote desktop software</td>\n",
       "      <td>8</td>\n",
       "      <td>Rust,95.4%,HTML,1.8%,CSS,1.7%,Other,1.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>algorithm-visualizer/algorithm-visualizer</td>\n",
       "      <td>🎆Interactive Online Platform that Visualizes A...</td>\n",
       "      <td>23</td>\n",
       "      <td>JavaScript,83.9%,SCSS,13.0%,HTML,1.2%,Other,1.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>academic/awesome-datascience</td>\n",
       "      <td>📝 An awesome Data Science repository to learn ...</td>\n",
       "      <td>141</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>megaease/easegress</td>\n",
       "      <td>A Cloud Native traffic orchestration system</td>\n",
       "      <td>14</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TheBobPony/getwindows11.tech</td>\n",
       "      <td>For the website</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>donnemartin/system-design-primer</td>\n",
       "      <td>Learn how to design large-scale systems. Prep ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kwai/DouZero</td>\n",
       "      <td>[ICML 2021] DouZero: Mastering DouDizhu with S...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python,98.8%,Shell,1.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>programthink/opensource</td>\n",
       "      <td>【编程随想】收藏的开源项目清单</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>facebookresearch/xcit</td>\n",
       "      <td>Official code Cross-Covariance Image Transform...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>githubdev03/RDP</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tailwindlabs/tailwindcss</td>\n",
       "      <td>A utility-first CSS framework for rapid UI dev...</td>\n",
       "      <td>177</td>\n",
       "      <td>JavaScript,79.1%,CSS,16.1%,HTML,4.7%,Other,0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>coqui-ai/TTS</td>\n",
       "      <td>🐸💬 - a deep learning toolkit for Text-to-Speec...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>v2fly/v2ray-core</td>\n",
       "      <td>A platform for building proxies to bypass netw...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nothings/stb</td>\n",
       "      <td>stb single-file public domain libraries for C/C++</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mltframework/shotcut</td>\n",
       "      <td>cross-platform (Qt), open-source (GPLv3) video...</td>\n",
       "      <td>42</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>flutter/flutter</td>\n",
       "      <td>Flutter makes it easy and fast to build beauti...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0                                   programthink/zhao   \n",
       "1       AkashSingh3031/The-Complete-FAANG-Preparation   \n",
       "2                            CaffeineMC/sodium-fabric   \n",
       "3                                          n8n-io/n8n   \n",
       "4                              facebookresearch/AugLy   \n",
       "5                     vxunderground/MalwareSourceCode   \n",
       "6   abuanwar072/Flutter-Responsive-Admin-Panel-or-...   \n",
       "7                     EssayKillerBrain/EssayKiller_V2   \n",
       "8                             organicmaps/organicmaps   \n",
       "9                                   rustdesk/rustdesk   \n",
       "10          algorithm-visualizer/algorithm-visualizer   \n",
       "11                       academic/awesome-datascience   \n",
       "12                                 megaease/easegress   \n",
       "13                       TheBobPony/getwindows11.tech   \n",
       "14                   donnemartin/system-design-primer   \n",
       "15                                       kwai/DouZero   \n",
       "16                            programthink/opensource   \n",
       "17                              facebookresearch/xcit   \n",
       "18                                    githubdev03/RDP   \n",
       "19                           tailwindlabs/tailwindcss   \n",
       "20                                       coqui-ai/TTS   \n",
       "21                                   v2fly/v2ray-core   \n",
       "22                                       nothings/stb   \n",
       "23                               mltframework/shotcut   \n",
       "24                                    flutter/flutter   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0                        【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵                  -   \n",
       "1   This repository contains all the DSA (Data-Str...                  -   \n",
       "2   A Fabric mod designed to improve frame rates a...                  -   \n",
       "3   Free and open fair-code licensed node based Wo...                174   \n",
       "4   A data augmentations library for audio, image,...                  5   \n",
       "5   Collection of malware source code for a variet...                  -   \n",
       "6   Responsive Admin Panel or Dashboard using Flutter                  -   \n",
       "7                      基于开源GPT2.0的初代创作型人工智能 | 可扩展、可进化                  -   \n",
       "8   🍃 Organic Maps is a better fork of MAPS.ME, an...                  -   \n",
       "9                 Yet another remote desktop software                  8   \n",
       "10  🎆Interactive Online Platform that Visualizes A...                 23   \n",
       "11  📝 An awesome Data Science repository to learn ...                141   \n",
       "12        A Cloud Native traffic orchestration system                 14   \n",
       "13                                    For the website                  -   \n",
       "14  Learn how to design large-scale systems. Prep ...                  -   \n",
       "15  [ICML 2021] DouZero: Mastering DouDizhu with S...                  -   \n",
       "16                                    【编程随想】收藏的开源项目清单                  3   \n",
       "17  Official code Cross-Covariance Image Transform...                  -   \n",
       "18                                                  -                  -   \n",
       "19  A utility-first CSS framework for rapid UI dev...                177   \n",
       "20  🐸💬 - a deep learning toolkit for Text-to-Speec...                  -   \n",
       "21  A platform for building proxies to bypass netw...                  -   \n",
       "22  stb single-file public domain libraries for C/C++                  -   \n",
       "23  cross-platform (Qt), open-source (GPLv3) video...                 42   \n",
       "24  Flutter makes it easy and fast to build beauti...                  -   \n",
       "\n",
       "                                        Language used  \n",
       "0                                                   -  \n",
       "1                                                   -  \n",
       "2                                                   -  \n",
       "3   TypeScript,94.9%,Vue,4.9%,SCSS,0.1%,JavaScript...  \n",
       "4                                       Python,100.0%  \n",
       "5                                                   -  \n",
       "6                                                   -  \n",
       "7                                                   -  \n",
       "8                                                   -  \n",
       "9            Rust,95.4%,HTML,1.8%,CSS,1.7%,Other,1.1%  \n",
       "10   JavaScript,83.9%,SCSS,13.0%,HTML,1.2%,Other,1.9%  \n",
       "11                                                  -  \n",
       "12                                                  -  \n",
       "13                                                  -  \n",
       "14                                                  -  \n",
       "15                            Python,98.8%,Shell,1.2%  \n",
       "16                                                  -  \n",
       "17                                                  -  \n",
       "18                                                  -  \n",
       "19    JavaScript,79.1%,CSS,16.1%,HTML,4.7%,Other,0.1%  \n",
       "20                                                  -  \n",
       "21                                                  -  \n",
       "22                                                  -  \n",
       "23                                                  -  \n",
       "24                                                  -  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat empty list:\n",
    "\n",
    "urls=[]\n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "# Scrap the url:\n",
    "\n",
    "for i in range(1,26):\n",
    "    for j in driver.find_elements_by_xpath(\"/html/body/div[4]/main/div[3]/div/div[2]/article[{}]/h1/a\".format(i)):\n",
    "        urls.append(j.get_attribute(\"href\"))\n",
    "\n",
    "# Scrap the Repository_title :         \n",
    "        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        title=driver.find_element_by_xpath(\"/html/body/div[4]/div/main/div[1]/div[1]/div/h1\")\n",
    "        Repository_title.append(title.text.replace(\"\\n\",\"\"))\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append(\"-\")\n",
    "        \n",
    "# Scrap the Repository_description :\n",
    "        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        about=driver.find_element_by_xpath(\"/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[1]/div/p\")\n",
    "        Repository_description.append(about.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append(\"-\")\n",
    "\n",
    "# Scrap the Contributors_count :        \n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        count=driver.find_element_by_xpath(\"/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[5]/div/h2/a/span\")\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append(\"-\")\n",
    "\n",
    "# Scrap the Language_used :        \n",
    "        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        langauge=driver.find_element_by_xpath(\"/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[6]/div/ul\")\n",
    "        Language_used.append(langauge.text.replace(\"\\n\",\",\"))\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append(\"-\")\n",
    "        \n",
    "\n",
    "# Creating DataFrame:        \n",
    "        \n",
    "DataFrame=pd.DataFrame({\"Repository title\":Repository_title,\"Repository description\":Repository_description,\n",
    "                        \"Contributors count\":Contributors_count,\"Language used\":Language_used})\n",
    "DataFrame\n",
    "\n",
    "# Saving the data: \n",
    "\n",
    "DataFrame.to_csv(\"trending repositories on Github\")\n",
    "\n",
    "# close the driver:\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver and maximize the page:\n",
    "\n",
    "driver=webdriver.Chrome(\"Chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# go into url:\n",
    "\n",
    "driver.get(\"https://www.billboard.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on menue button:\n",
    "\n",
    "menu_button=driver.find_element_by_id(\"toggle-menu-action\")\n",
    "menu_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on charts button:\n",
    "\n",
    "charts_button=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/ul/li[1]/a\")\n",
    "charts_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on hot_100 button:\n",
    "\n",
    "hot_100=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/ul/li[1]/span/span/span/span[1]/ul/li[1]/a\")\n",
    "hot_100.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Things A Man Oughta Know</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td></td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Country Again</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Drunk (And I Don't Wanna Go Home)</td>\n",
       "      <td>Elle King &amp; Miranda Lambert</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>If You Want To</td>\n",
       "      <td>Lil Baby &amp; Lil Durk</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Seeing Green</td>\n",
       "      <td>Nicki Minaj, Drake &amp; Lil Wayne</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Song name  \\\n",
       "0                               Butter   \n",
       "1                             Good 4 U   \n",
       "2                           Levitating   \n",
       "3                              Peaches   \n",
       "4                  Leave The Door Open   \n",
       "..                                 ...   \n",
       "104           Things A Man Oughta Know   \n",
       "105                      Country Again   \n",
       "106  Drunk (And I Don't Wanna Go Home)   \n",
       "107                     If You Want To   \n",
       "108                       Seeing Green   \n",
       "\n",
       "                                        Artist name Last week rank Peak rank  \\\n",
       "0                                               BTS              1         1   \n",
       "1                                    Olivia Rodrigo                        2   \n",
       "2                         Dua Lipa Featuring DaBaby                        3   \n",
       "3    Justin Bieber Featuring Daniel Caesar & Giveon              6         1   \n",
       "4          Silk Sonic (Bruno Mars & Anderson .Paak)              4         1   \n",
       "..                                              ...            ...       ...   \n",
       "104                                   Lainey Wilson                       93   \n",
       "105                                    Thomas Rhett             89        73   \n",
       "106                     Elle King & Miranda Lambert             92        79   \n",
       "107                             Lil Baby & Lil Durk                        -   \n",
       "108                  Nicki Minaj, Drake & Lil Wayne             67        12   \n",
       "\n",
       "    Weeks on board  \n",
       "0                3  \n",
       "1                1  \n",
       "2                2  \n",
       "3               12  \n",
       "4               14  \n",
       "..             ...  \n",
       "104             93  \n",
       "105              6  \n",
       "106              7  \n",
       "107             99  \n",
       "108              4  \n",
       "\n",
       "[109 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating empty list:\n",
    "    \n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week=[]\n",
    "Peak_rank=[]\n",
    "Weeks_board=[]\n",
    "\n",
    "# Scrap song_name:\n",
    "\n",
    "for i in range(1,110):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li[{}]/button/span[2]/span[1]\".format(i))\n",
    "        Song_name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Song_name.append(\"-\")\n",
    "\n",
    "# Scrap Artist_name:        \n",
    "        \n",
    "for i in range(1,110):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li[{}]/button/span[2]/span[2]\".format(i))\n",
    "        Artist_name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist_name.append(\"-\")\n",
    "        \n",
    "# Scrap Last_week:\n",
    "        \n",
    "for i in range(1,110):\n",
    "    try:\n",
    "        week=driver.find_element_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li[{}]/button/div/div[1]\".format(i))\n",
    "        Last_week.append(week.text)\n",
    "    except NoSuchElementException:\n",
    "        Last_week.append(\"-\")\n",
    "        \n",
    "# Scrap Peak_rank:\n",
    "        \n",
    "for i in range(1,110):\n",
    "    try:\n",
    "        rank=driver.find_element_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li[{}]/button/div/div[2]\".format(i))\n",
    "        Peak_rank.append(rank.text)\n",
    "    except NoSuchElementException:\n",
    "        Peak_rank.append(\"-\")\n",
    "        \n",
    "# Scrap Weeks_board:\n",
    "        \n",
    "for i in range(1,110):\n",
    "    try:\n",
    "        board=driver.find_element_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li[{}]/button/div/div[3]\".format(i))\n",
    "        Weeks_board.append(board.text)\n",
    "    except NoSuchElementException:\n",
    "        Weeks_board.append(\"-\")\n",
    "        \n",
    "# Creating dataframe:\n",
    "        \n",
    "DataFrame=pd.DataFrame({\"Song name\":Song_name,\"Artist name\":Artist_name,\"Last week rank\":Last_week,\n",
    "                        \"Peak rank\":Peak_rank,\"Weeks on board\":Weeks_board})\n",
    "DataFrame\n",
    "\n",
    "# Saving the dataframe:\n",
    "\n",
    "DataFrame.to_csv(\"100 songs on billboard\")\n",
    "\n",
    "# close driver:\n",
    "\n",
    "DataFrame.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting and maximize the url page:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# get into url:\n",
    "driver.get(\" https://www.naukri.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type Data Science into skill's bar:\n",
    "\n",
    "skill=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "skill.send_keys(\"Data science\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search_button:\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills they hire for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data science analyst</td>\n",
       "      <td>CRED</td>\n",
       "      <td>Analytical skillsHealth insurancedata scienceD...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUSINESS ANALYST -DATA SCIENCE-CONSUMER</td>\n",
       "      <td>BRIDGEi2i Analytics Solutions Private Limited</td>\n",
       "      <td>Business Analystdata scienceAnalyticalMachine ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>JPMorgan Services India Pvt. Ltd</td>\n",
       "      <td>Data ScienceRArtificial IntelligenceExplorator...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Content Developer</td>\n",
       "      <td>Data is Good</td>\n",
       "      <td>Data SciencePython DashExcelContent Developmen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science- Associate Data Scientist</td>\n",
       "      <td>Jet2 Travel Technologies Pvt. Ltd.</td>\n",
       "      <td>Data Sciencepythonmachine learning</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Intern (remote)</td>\n",
       "      <td>Amploy.io</td>\n",
       "      <td>Data ScienceApplication ProgrammingSoftware De...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>MJB Technology Solutions</td>\n",
       "      <td>Computer scienceBusiness administrationAnalyst...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Opening For Data Data Science Analyst &amp; Data A...</td>\n",
       "      <td>Motilal Oswal Financial Services</td>\n",
       "      <td>Data ScienceMIS PreparationData AnalysisAdvanc...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analyst -Data Science ( Supply Chain)</td>\n",
       "      <td>Eaton Corporation</td>\n",
       "      <td>Power BiMachine LearningPython</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Science &amp; Analysis (Technology Management)</td>\n",
       "      <td>Morgan Stanley Advantage Services</td>\n",
       "      <td>UnixData analysisLegal complianceWealth manage...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Web Development/Data Science Trainee</td>\n",
       "      <td>Musubi Management Private Limited</td>\n",
       "      <td>Data ScienceWeb Development</td>\n",
       "      <td>Bangalore/Bengaluru( 5th block Koramangala )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Senior Director Data Science - Bangalore</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>Data ScienceExploratory Data AnalysisArtificia...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Science Analyst-Insurance Data Sciences</td>\n",
       "      <td>Xceedance</td>\n",
       "      <td>-</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Reliance Jio Infocomm Ltd.</td>\n",
       "      <td>Data analysisStatistical modelingdata scienceM...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Designation  \\\n",
       "0                                data science analyst   \n",
       "1             BUSINESS ANALYST -DATA SCIENCE-CONSUMER   \n",
       "2                                Data Science Analyst   \n",
       "3                      Data Science Content Developer   \n",
       "4                                                   -   \n",
       "5              Data Science- Associate Data Scientist   \n",
       "6                        Data Science Intern (remote)   \n",
       "7                                                   -   \n",
       "8                                Data Science Analyst   \n",
       "9                                                   -   \n",
       "10  Opening For Data Data Science Analyst & Data A...   \n",
       "11              Analyst -Data Science ( Supply Chain)   \n",
       "12    Data Science & Analysis (Technology Management)   \n",
       "13                                                  -   \n",
       "14                                                  -   \n",
       "15               Web Development/Data Science Trainee   \n",
       "16           Senior Director Data Science - Bangalore   \n",
       "17                                                  -   \n",
       "18       Data Science Analyst-Insurance Data Sciences   \n",
       "19                              Data Science Engineer   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                             CRED   \n",
       "1    BRIDGEi2i Analytics Solutions Private Limited   \n",
       "2                 JPMorgan Services India Pvt. Ltd   \n",
       "3                                     Data is Good   \n",
       "4                                                -   \n",
       "5               Jet2 Travel Technologies Pvt. Ltd.   \n",
       "6                                        Amploy.io   \n",
       "7                                                -   \n",
       "8                         MJB Technology Solutions   \n",
       "9                                                -   \n",
       "10                Motilal Oswal Financial Services   \n",
       "11                               Eaton Corporation   \n",
       "12               Morgan Stanley Advantage Services   \n",
       "13                                               -   \n",
       "14                                               -   \n",
       "15               Musubi Management Private Limited   \n",
       "16  Optum Global Solutions (India) Private Limited   \n",
       "17                                               -   \n",
       "18                                       Xceedance   \n",
       "19                      Reliance Jio Infocomm Ltd.   \n",
       "\n",
       "                                 Skills they hire for  \\\n",
       "0   Analytical skillsHealth insurancedata scienceD...   \n",
       "1   Business Analystdata scienceAnalyticalMachine ...   \n",
       "2   Data ScienceRArtificial IntelligenceExplorator...   \n",
       "3   Data SciencePython DashExcelContent Developmen...   \n",
       "4                                                   -   \n",
       "5                  Data Sciencepythonmachine learning   \n",
       "6   Data ScienceApplication ProgrammingSoftware De...   \n",
       "7                                                   -   \n",
       "8   Computer scienceBusiness administrationAnalyst...   \n",
       "9                                                   -   \n",
       "10  Data ScienceMIS PreparationData AnalysisAdvanc...   \n",
       "11                     Power BiMachine LearningPython   \n",
       "12  UnixData analysisLegal complianceWealth manage...   \n",
       "13                                                  -   \n",
       "14                                                  -   \n",
       "15                        Data ScienceWeb Development   \n",
       "16  Data ScienceExploratory Data AnalysisArtificia...   \n",
       "17                                                  -   \n",
       "18                                                  -   \n",
       "19  Data analysisStatistical modelingdata scienceM...   \n",
       "\n",
       "                                        Location  \n",
       "0                            Bangalore/Bengaluru  \n",
       "1                            Bangalore/Bengaluru  \n",
       "2                                         Mumbai  \n",
       "3                            Bangalore/Bengaluru  \n",
       "4                                              -  \n",
       "5                                           Pune  \n",
       "6                            Bangalore/Bengaluru  \n",
       "7                                              -  \n",
       "8                                           Pune  \n",
       "9                                              -  \n",
       "10                                        Mumbai  \n",
       "11                                          Pune  \n",
       "12                                        Mumbai  \n",
       "13                                             -  \n",
       "14                                             -  \n",
       "15  Bangalore/Bengaluru( 5th block Koramangala )  \n",
       "16                           Bangalore/Bengaluru  \n",
       "17                                             -  \n",
       "18                              Gurgaon/Gurugram  \n",
       "19                                        Mumbai  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty list:\n",
    "\n",
    "urls=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "key_skill=[]\n",
    "Location=[]\n",
    "\n",
    "# scraping url:\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "# Scrap Designation:\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        designation=driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        Designation.append(designation.text)\n",
    "    except NoSuchElementException:\n",
    "        Designation.append(\"-\")\n",
    "        \n",
    "# Scrap Company_Name:\n",
    "        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        comp=driver.find_element_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "        Company.append(comp.text)\n",
    "    except NoSuchElementException:\n",
    "        Company.append(\"-\")\n",
    "        \n",
    "# Scrap key_skill:\n",
    "        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        key=driver.find_element_by_xpath(\"/html/body/div[1]/main/div[2]/div[2]/section[2]/div[4]/div[2]\")\n",
    "        key_skill.append(key.text)\n",
    "    except NoSuchElementException:\n",
    "        key_skill.append(\"-\")\n",
    "\n",
    "# Scrap Location:        \n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        loc=driver.find_element_by_xpath(\"/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[3]/span/a\")\n",
    "        Location.append(loc.text)\n",
    "    except NoSuchElementException:\n",
    "        Location.append(\"-\")\n",
    "        \n",
    "# Creating DataFrame:\n",
    "        \n",
    "DataFrame=pd.DataFrame({\"Designation\":Designation,\"Company\":Company,\"Skills they hire for\":key_skill,\"Location\":Location})\n",
    "DataFrame\n",
    "\n",
    "\n",
    "# Saving data:\n",
    "\n",
    "DataFrame.to_csv(\"Data science recruiters from naukri\")\n",
    "\n",
    "# closing driver:\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# get into url:\n",
    "\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty list:\n",
    "\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "# Scrap book_name:\n",
    "\n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[{}]/td[2]\".format(i))\n",
    "        Book_name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Book_name.append(\"-\")\n",
    "        \n",
    "# Scrap Author_name:\n",
    "        \n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[{}]/td[3]\".format(i))\n",
    "        Author_name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append(\"-\")\n",
    "        \n",
    "# Scrap Volumes_name:\n",
    "        \n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        vol=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[{}]/td[4]\".format(i))\n",
    "        Volumes_sold.append(vol.text)\n",
    "    except NoSuchElementException:\n",
    "        Volumes_sold.append(\"-\")\n",
    "        \n",
    "# Scrap publisher:\n",
    "        \n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        pub=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[{}]/td[5]\".format(i))\n",
    "        Publisher.append(pub.text)\n",
    "    except NoSuchElementException:\n",
    "        Publisher.append(\"-\")\n",
    "        \n",
    "# Scrap Genre:\n",
    "        \n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        gen=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr[{}]/td[6]\".format(i))\n",
    "        Genre.append(gen.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append(\"-\")\n",
    "        \n",
    "# creating dataframe:\n",
    "        \n",
    "DataFrame=pd.DataFrame({\"Book name\":Book_name,\"Author name\":Author_name,\"Volumes sold\":Volumes_sold,\n",
    "                        \"Publisher\":Publisher,\"Genre\":Genre})\n",
    "DataFrame\n",
    "\n",
    "# save the dataframe:\n",
    "\n",
    "DataFrame.to_csv(\"Highest selling novels\")\n",
    "\n",
    "# close the dataframe:\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting the webdriver and maximize the window:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# get into url:\n",
    "\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,825,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>865,452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>875,270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>224,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>168,083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.3  1,825,442  \n",
       "1    51 min     8.7    865,452  \n",
       "2    44 min     8.2    875,270  \n",
       "3    60 min     7.6    262,969  \n",
       "4    43 min     7.6    224,366  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     44,602  \n",
       "96   50 min     7.8     55,117  \n",
       "97   42 min       8    168,083  \n",
       "98   45 min     7.1     34,924  \n",
       "99  572 min     8.6    191,785  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an empty list:\n",
    "\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "# Scrap Name:\n",
    "\n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[{}]/div[2]/h3/a\".format(i))\n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append(\"-\")\n",
    "\n",
    "# Scrap year_span:\n",
    "\n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        span=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[{}]/div[2]/h3/span[2]\".format(i))\n",
    "        Year_span.append(span.text)\n",
    "    except NoSuchElementException:\n",
    "        Year_span.append(\"-\")\n",
    "\n",
    "        \n",
    "# Scrap Genera:\n",
    "\n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        gen=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[{}]/div[2]/p[1]/span[5]\".format(i))\n",
    "        Genre.append(gen.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append(\"-\")\n",
    "        \n",
    "# Scrap Run_time:\n",
    "        \n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        time=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[{}]/div[2]/p[1]/span[3]\".format(i))\n",
    "        Run_time.append(time.text)\n",
    "    except NoSuchElementException:\n",
    "        Run_time.append(\"-\")\n",
    "        \n",
    "# Scrap Rating:\n",
    "        \n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        rate=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[{}]/div[2]/div[1]/div[1]/span[2]\".format(i))\n",
    "        Ratings.append(rate.text)\n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"-\")\n",
    "        \n",
    "# Scrap votes:\n",
    "\n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        vote=driver.find_element_by_xpath(\"/html/body/div[4]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div[{}]/div[2]/p[4]/span[2]\".format(i))\n",
    "        Votes.append(vote.text)\n",
    "    except NoSuchElementException:\n",
    "        Votes.append(\"-\")\n",
    "        \n",
    "# creating a dataframe:\n",
    "\n",
    "DataFrame=pd.DataFrame({\"Name\":Name,\"Year span\":Year_span,\"Genre\":Genre,\n",
    "                        \"Run time\":Run_time,\"Ratings\":Ratings,\"Votes\":Votes})\n",
    "DataFrame\n",
    "\n",
    "# Saving the data:\n",
    "\n",
    "DataFrame.to_csv(\"tv series\")\n",
    "\n",
    "# closing the driver:\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION:10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "    \n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting and maximizing the web driver:\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "\n",
    "#get into urls:\n",
    "\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click all dataset:\n",
    "\n",
    "dataset=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/span/b/a\")\n",
    "dataset.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset name      Data type                  Task  \\\n",
       "0                             Abalone  Multivariate        Classification    \n",
       "1                               Adult  Multivariate        Classification    \n",
       "2                           Annealing  Multivariate        Classification    \n",
       "3        Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "4                          Arrhythmia  Multivariate        Classification    \n",
       "..                                ...            ...                   ...   \n",
       "583  in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "584               Gait Classification  Multivariate        Classification    \n",
       "585         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "586         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587      Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "                  Attribute type No of instances No of attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "583                                       12684              23   2020   \n",
       "584                        Real              48             321   2020   \n",
       "585                        Real             731            1068   2021   \n",
       "586                        Real             731            1068   2021   \n",
       "587                        Real             557               5   2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an empty list:\n",
    "\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_instances=[]\n",
    "No_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "# Scrap dataset name:\n",
    "\n",
    "for i in range(2,590):\n",
    "    try:\n",
    "        name=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{}]/td[1]/table/tbody/tr/td[2]/p/b/a\".format(i))\n",
    "        Dataset_name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append(\"-\")\n",
    "\n",
    "# Scrap data type:\n",
    "\n",
    "for i in range(2,590):\n",
    "    try:\n",
    "        types=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{}]/td[2]/p\".format(i))\n",
    "        Data_type.append(types.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append(\"-\")\n",
    "        \n",
    "# Scrap task:\n",
    "\n",
    "for i in range(2,590):\n",
    "    try:\n",
    "        task=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{}]/td[3]/p\".format(i))\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append(\"-\")\n",
    "        \n",
    "# Scrap attribute name:\n",
    "\n",
    "for i in range(2,590):\n",
    "    try:\n",
    "        typ=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{}]/td[4]/p\".format(i))\n",
    "        Attribute_type.append(typ.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append(\"-\")\n",
    "        \n",
    "# Scrap no of instances:\n",
    "\n",
    "for i in range(2,590):\n",
    "    try:\n",
    "        inst=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{}]/td[5]/p\".format(i))\n",
    "        No_instances.append(inst.text)\n",
    "    except NoSuchElementException:\n",
    "        No_instances.append(\"-\")\n",
    "        \n",
    "# Scrap no of attribute:\n",
    "\n",
    "for i in range(2,590):\n",
    "    try:\n",
    "        attr=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{}]/td[6]/p\".format(i))\n",
    "        No_attribute.append(attr.text)\n",
    "    except NoSuchElementException:\n",
    "        No_attribute.append(\"-\")\n",
    "        \n",
    "# Scrap year:        \n",
    "        \n",
    "for i in range(2,590):\n",
    "    try:\n",
    "        year=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[{}]/td[7]/p\".format(i))\n",
    "        Year.append(year.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append(\"-\")\n",
    "        \n",
    "# Creating a dataframe:\n",
    "        \n",
    "DataFrame=pd.DataFrame({\"Dataset name\":Dataset_name,\"Data type\":Data_type,\"Task\":Task,\"Attribute type\":Attribute_type,\n",
    "                        \"No of instances\":No_instances,\"No of attribute\":No_attribute,\"Year\":Year})\n",
    "DataFrame\n",
    "\n",
    "# saving the data:\n",
    "\n",
    "DataFrame.to_csv(\"UCI machine learning repositories\")\n",
    "\n",
    "# closing driver:\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
